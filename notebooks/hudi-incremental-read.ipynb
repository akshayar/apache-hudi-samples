{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ace94f6",
   "metadata": {},
   "source": [
    "# Copy Jars to hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb584d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Thes command on master node of EMR\n",
    "hdfs dfs -mkdir -p /usr/lib/hudi/\n",
    "hdfs dfs -mkdir -p /usr/lib/spark/external/lib/\n",
    "hdfs dfs -copyFromLocal /usr/lib/hudi/hudi-spark-bundle.jar /usr/lib/hudi/hudi-spark-bundle.jar\n",
    "hdfs dfs -copyFromLocal /usr/lib/spark/external/lib/spark-avro.jar /usr/lib/spark/external/lib/spark-avro.jar\n",
    "hdfs dfs -ls /usr/lib/hudi/hudi-spark-bundle.jar /usr/lib/spark/external/lib/spark-avro.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc83894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.serializer': 'org.apache.spark.serializer.KryoSerializer', 'spark.sql.hive.convertMetastoreParquet': 'false', 'spk.dynamicAllocation.maxExecutors': '10', 'spark.jars': 'hdfs:///usr/lib/hudi/hudi-spark-bundle.jar,hdfs:///usr/lib/spark/external/lib/spark-avro.jar'}, 'proxyUser': 'user_rawaaksh', 'kind': 'spark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\"conf\":{\"spark.serializer\":\"org.apache.spark.serializer.KryoSerializer\",\n",
    "         \"spark.sql.hive.convertMetastoreParquet\":\"false\",\n",
    "         \"spk.dynamicAllocation.maxExecutors\":\"10\",\n",
    "         \"spark.jars\":\"hdfs:///usr/lib/hudi/hudi-spark-bundle.jar,hdfs:///usr/lib/spark/external/lib/spark-avro.jar\"\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eddac5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ec0d1a89824b71a58b8ec958784619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>16</td><td>application_1639488028357_0016</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-192-10-46.ap-south-1.compute.internal:20888/proxy/application_1639488028357_0016/\" class=\"emr-proxy-link\" emr-resource=\"j-YYQG025DA0AC\n",
       "\" application-id=\"application_1639488028357_0016\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-192-10-120.ap-south-1.compute.internal:8042/node/containerlogs/container_1639488028357_0016_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import org.apache.hudi.config.HoodieWriteConfig\n",
      "import org.apache.hudi.config.HoodieWriteConfig._\n",
      "import org.apache.hudi.hive.MultiPartKeysValueExtractor\n",
      "import org.apache.hudi.DataSourceWriteOptions\n",
      "import org.apache.hudi.DataSourceWriteOptions._\n",
      "import org.apache.hudi.DataSourceReadOptions\n",
      "import org.apache.hudi.DataSourceReadOptions._\n",
      "import org.apache.hudi.QuickstartUtils._\n",
      "import org.apache.spark.sql.types._\n",
      "import org.apache.spark.sql.functions._\n",
      "import org.apache.spark.sql.{DataFrame, Row, SaveMode}\n",
      "import org.apache.spark.sql.catalyst.encoders.RowEncoder\n",
      "import org.apache.spark.sql.types.{LongType, StringType, StructField, StructType}\n",
      "import org.apache.spark.sql.SparkSession\n",
      "import org.apache.log4j.Logger\n",
      "import org.apache.spark.storage.StorageLevel\n",
      "import java.util.Date\n",
      "import java.text.SimpleDateFormat\n",
      "import org.apache.spark.sql.streaming._\n",
      "import org.apache.spark.sql.streaming.StreamingQueryListener\n",
      "import org.apache.spark.sql.streaming.StreamingQueryListener._\n",
      "import java.util.concurrent.TimeUnit\n",
      "import org.apache.hudi.keygen._\n",
      "import java.util._\n",
      "import java.time._\n",
      "import java.time.format._\n"
     ]
    }
   ],
   "source": [
    "import org.apache.hudi.config.HoodieWriteConfig\n",
    "import org.apache.hudi.config.HoodieWriteConfig._\n",
    "import org.apache.hudi.hive.MultiPartKeysValueExtractor\n",
    "import org.apache.hudi.DataSourceWriteOptions\n",
    "import org.apache.hudi.DataSourceWriteOptions._\n",
    "import org.apache.hudi.DataSourceReadOptions\n",
    "import org.apache.hudi.DataSourceReadOptions._\n",
    "import org.apache.hudi.QuickstartUtils._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.{DataFrame, Row, SaveMode}\n",
    "import org.apache.spark.sql.catalyst.encoders.RowEncoder\n",
    "import org.apache.spark.sql.types.{LongType, StringType, StructField, StructType}\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.log4j.Logger\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "import java.util.Date\n",
    "import java.text.SimpleDateFormat\n",
    "import org.apache.spark.sql.streaming._\n",
    "import org.apache.spark.sql.streaming.StreamingQueryListener\n",
    "import org.apache.spark.sql.streaming.StreamingQueryListener._\n",
    "import java.util.concurrent.TimeUnit\n",
    "import org.apache.hudi.keygen._\n",
    "import java.util._\n",
    "import java.time._\n",
    "import java.time.format._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ea684f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb42bf6d4480443481d32825dcc6026c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import spark.implicits._\n",
      "s3_bucket: String = akshaya-hudi-experiments\n",
      "sourceHudiTableName: String = equity_trade_records_cow\n",
      "targetTableType: String = COW\n",
      "targetTableNamePrefix: String = hudi_trade_info_derived\n",
      "targetTableName: String = hudi_trade_info_derived_cow\n",
      "hudiDatabaseName: String = demohudi\n",
      "dsWriteOptionType: String = COPY_ON_WRITE\n",
      "sourceHudiTablePath: String = s3://akshaya-hudi-experiments/demo/hudi/equity_trade_records_cow\n"
     ]
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "// Spark Shell -- hardcode these parameters\n",
    "var s3_bucket = \"akshaya-hudi-experiments\"\n",
    "var sourceHudiTableName =  \"equity_trade_records_cow\"\n",
    "var targetTableType = \"COW\"\n",
    "var targetTableNamePrefix = \"hudi_trade_info_derived\"\n",
    "var targetTableName = targetTableNamePrefix + \"_cow\"\n",
    "var hudiDatabaseName = \"demohudi\"\n",
    "var dsWriteOptionType = DataSourceWriteOptions.COW_STORAGE_TYPE_OPT_VAL\n",
    "if (targetTableType.equals(\"COW\")) {\n",
    "      targetTableName = targetTableNamePrefix + \"_cow\"\n",
    "      dsWriteOptionType = DataSourceWriteOptions.COW_STORAGE_TYPE_OPT_VAL\n",
    "} else if (targetTableType.equals(\"MOR\")) {\n",
    "      targetTableName = targetTableNamePrefix + \"_mor\"\n",
    "      dsWriteOptionType = DataSourceWriteOptions.MOR_STORAGE_TYPE_OPT_VAL\n",
    "}\n",
    "val sourceHudiTablePath = s\"s3://$s3_bucket/demo/hudi/\" + sourceHudiTableName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a0f6c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bb125b196742ca99def88ee72d33a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res196: java.time.LocalDateTime = 2021-12-14T16:34:49.373\n",
      "date: String = 20211214161449\n",
      "sql: String = \"select max(_hoodie_commit_time) as commitTime from  equity_trade_records_cow where  _hoodie_commit_time < 20211214161449 \"\n",
      "commits: Array[String] = Array(20211214154500)\n",
      "beginTime: String = 20211214154500\n"
     ]
    }
   ],
   "source": [
    "LocalDateTime.now(ZoneOffset.UTC)\n",
    "val date=LocalDateTime.now(ZoneOffset.UTC).minusMinutes(20).format(DateTimeFormatter.ofPattern(\"yyyyMMddHHmmss\")) \n",
    "spark.read.format(\"hudi\").load(sourceHudiTablePath).createOrReplaceTempView(sourceHudiTableName)\n",
    "val sql=(s\"select max(_hoodie_commit_time) as commitTime from  $sourceHudiTableName where  _hoodie_commit_time < $date \")\n",
    "val commits = spark.sql(sql).map(k => k.getString(0)).take(10)  \n",
    "var beginTime =  Optional.ofNullable(commits(0) ).orElse(date)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61b79c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d549be5d54b4e65a8561e9dd67b449d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hudiTableRecordKey: String = record_key\n",
      "hudiTablePrecombineKey: String = trade_datetime\n",
      "hudiHiveTablePartitionKey: String = symbol,day,hour\n",
      "targetHudiTablePath: String = s3://akshaya-hudi-experiments/demo/hudi/hudi_trade_info_derived_cow\n",
      "hudiDatabaseName.targetTableName:demohudi.hudi_trade_info_derived_cow\n",
      "targetHudiTablePath:s3://akshaya-hudi-experiments/demo/hudi/hudi_trade_info_derived_cow\n",
      "hudiTablePrecombineKey:trade_datetime\n",
      "hudiHiveTablePartitionKey:symbol,day,hour\n",
      "incrementalDF: org.apache.spark.sql.DataFrame = [_hoodie_commit_time: string, _hoodie_commit_seqno: string ... 15 more fields]\n",
      "+-------------------+--------------------+--------------------+----------------------+--------------------+---------------+------+--------+-----+----------+--------------------+------------+----------+--------------------+-------------------+---+----+\n",
      "|_hoodie_commit_time|_hoodie_commit_seqno|  _hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name|        tradeid|symbol|quantity|price| timestamp|         description|  tradername|traderfirm|          record_key|     trade_datetime|day|hour|\n",
      "+-------------------+--------------------+--------------------+----------------------+--------------------+---------------+------+--------+-----+----------+--------------------+------------+----------+--------------------+-------------------+---+----+\n",
      "|     20211214164543|20211214164543_2_233|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221665282|  AAPL|      85|   85|1639496188|Traded on Tue Dec...| AAPL trader| AAPL firm|211214221665282#1...|2021-12-14 15:36:28| 14|  15|\n",
      "|     20211214164543|20211214164543_2_234|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221642486|  AMZN|      26|   26|1639494695|Traded on Tue Dec...| AMZN trader| AMZN firm|211214221642486#1...|2021-12-14 15:11:35| 14|  15|\n",
      "|     20211214164543|20211214164543_2_235|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221602612|  INFY|      99|   99|1639494381|Traded on Tue Dec...| INFY trader| INFY firm|211214221602612#1...|2021-12-14 15:06:21| 14|  15|\n",
      "|     20211214164543|20211214164543_2_236|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221675103|  AMZN|      68|   68|1639497095|Traded on Tue Dec...| AMZN trader| AMZN firm|211214221675103#1...|2021-12-14 15:51:35| 14|  15|\n",
      "|     20211214164543|20211214164543_2_237|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221637687|  INFY|      11|   11|1639495602|Traded on Tue Dec...| INFY trader| INFY firm|211214221637687#1...|2021-12-14 15:26:42| 14|  15|\n",
      "|     20211214164543|20211214164543_2_238|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221628906|  AAPL|      90|   90|1639497425|Traded on Tue Dec...| AAPL trader| AAPL firm|211214221628906#1...|2021-12-14 15:57:05| 14|  15|\n",
      "|     20211214164543|20211214164543_2_239|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221606968|  AAPL|      08|   08|1639494343|Traded on Tue Dec...| AAPL trader| AAPL firm|211214221606968#1...|2021-12-14 15:05:43| 14|  15|\n",
      "|     20211214164720|20211214164720_2_147|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221607153| GOOGL|      60|   60|1639496399|Traded on Tue Dec...|GOOGL trader|GOOGL firm|211214221607153#1...|2021-12-14 15:39:59| 14|  15|\n",
      "|     20211214164720|20211214164720_2_148|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221702417|  INFY|      26|   26|1639496558|Traded on Tue Dec...| INFY trader| INFY firm|211214221702417#1...|2021-12-14 15:42:38| 14|  15|\n",
      "|     20211214164720|20211214164720_2_149|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221728993|  INFY|      71|   71|1639496812|Traded on Tue Dec...| INFY trader| INFY firm|211214221728993#1...|2021-12-14 15:46:52| 14|  15|\n",
      "|     20211214164720|20211214164720_2_150|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221723073|  AMZN|      37|   37|1639495322|Traded on Tue Dec...| AMZN trader| AMZN firm|211214221723073#1...|2021-12-14 15:22:02| 14|  15|\n",
      "|     20211214164720|20211214164720_2_151|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221733026|   IBM|      32|   32|1639494686|Traded on Tue Dec...|  IBM trader|  IBM firm|211214221733026#1...|2021-12-14 15:11:26| 14|  15|\n",
      "|     20211214164801|20211214164801_1_152|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221795776| GOOGL|      94|   94|1639496334|Traded on Tue Dec...|GOOGL trader|GOOGL firm|211214221795776#1...|2021-12-14 15:38:54| 14|  15|\n",
      "|     20211214164801|20211214164801_1_153|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221761302|   IBM|      31|   31|1639496227|Traded on Tue Dec...|  IBM trader|  IBM firm|211214221761302#1...|2021-12-14 15:37:07| 14|  15|\n",
      "|     20211214164801|20211214164801_1_154|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221754168|   IBM|      56|   56|1639497078|Traded on Tue Dec...|  IBM trader|  IBM firm|211214221754168#1...|2021-12-14 15:51:18| 14|  15|\n",
      "|     20211214164901|20211214164901_1_433|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221898663|  AAPL|      66|   66|1639495993|Traded on Tue Dec...| AAPL trader| AAPL firm|211214221898663#1...|2021-12-14 15:33:13| 14|  15|\n",
      "|     20211214164901|20211214164901_1_434|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221837508|  AMZN|      20|   20|1639496253|Traded on Tue Dec...| AMZN trader| AMZN firm|211214221837508#1...|2021-12-14 15:37:33| 14|  15|\n",
      "|     20211214164901|20211214164901_1_435|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221816595|  AAPL|      09|   09|1639496712|Traded on Tue Dec...| AAPL trader| AAPL firm|211214221816595#1...|2021-12-14 15:45:12| 14|  15|\n",
      "|     20211214164901|20211214164901_1_436|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221885860| GOOGL|      95|   95|1639496561|Traded on Tue Dec...|GOOGL trader|GOOGL firm|211214221885860#1...|2021-12-14 15:42:41| 14|  15|\n",
      "|     20211214164901|20211214164901_1_437|record_key:211214...|        day=14/hour=15|dd197b92-c822-4f4...|211214221810773|   IBM|      00|   00|1639497445|Traded on Tue Dec...|  IBM trader|  IBM firm|211214221810773#1...|2021-12-14 15:57:25| 14|  15|\n",
      "+-------------------+--------------------+--------------------+----------------------+--------------------+---------------+------+--------+-----+----------+--------------------+------------+----------+--------------------+-------------------+---+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- _hoodie_commit_time: string (nullable = true)\n",
      " |-- _hoodie_commit_seqno: string (nullable = true)\n",
      " |-- _hoodie_record_key: string (nullable = true)\n",
      " |-- _hoodie_partition_path: string (nullable = true)\n",
      " |-- _hoodie_file_name: string (nullable = true)\n",
      " |-- tradeid: string (nullable = true)\n",
      " |-- symbol: string (nullable = true)\n",
      " |-- quantity: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- tradername: string (nullable = true)\n",
      " |-- traderfirm: string (nullable = true)\n",
      " |-- record_key: string (nullable = true)\n",
      " |-- trade_datetime: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- hour: string (nullable = true)\n",
      "\n",
      "commitTimeDF: org.apache.spark.sql.DataFrame = [committime: bigint]\n",
      "newbeginTime: Array[String] = Array(20211214164901)\n",
      "maxTimeStamp: String = 20211214164901\n",
      "20211214164901\n"
     ]
    }
   ],
   "source": [
    "val hudiTableRecordKey = \"record_key\"\n",
    "val hudiTablePrecombineKey = \"trade_datetime\"\n",
    "val hudiHiveTablePartitionKey = \"symbol,day,hour\"\n",
    "val targetHudiTablePath = s\"s3://$s3_bucket/demo/hudi/\" + targetTableName\n",
    "println(\"hudiDatabaseName.targetTableName:\" + hudiDatabaseName+\".\"+targetTableName)\n",
    "println(\"targetHudiTablePath:\" + targetHudiTablePath)\n",
    "println(\"hudiTablePrecombineKey:\" + hudiTablePrecombineKey)    \n",
    "println(\"hudiHiveTablePartitionKey:\" + hudiHiveTablePartitionKey)\n",
    "\n",
    "val incrementalDF = (spark.read.format(\"hudi\")\n",
    "        .option(QUERY_TYPE_OPT_KEY, QUERY_TYPE_INCREMENTAL_OPT_VAL)\n",
    "        .option(BEGIN_INSTANTTIME_OPT_KEY, beginTime)\n",
    "        .load(sourceHudiTablePath))\n",
    "incrementalDF.show()\n",
    "incrementalDF.printSchema()\n",
    "\n",
    "val commitTimeDF=incrementalDF.select(unix_timestamp(col(\"_hoodie_commit_time\"),\"yyyyMMddHHmmss\").as(\"committime\"))\n",
    "val newbeginTime = commitTimeDF.agg(max(commitTimeDF.col(\"committime\"))).select(from_unixtime(col(\"max(committime)\"),\"yyyyMMddHHmmss\")).map(k => k.getString(0)).take(1)\n",
    "val maxTimeStamp=newbeginTime(0)\n",
    "if(maxTimeStamp !=null){\n",
    "    beginTime=maxTimeStamp\n",
    "}\n",
    "println(beginTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1924494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0cb20f62a44ae1bf150e8d89b5a369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: Unit = ()\n",
      "Saved data s3://akshaya-hudi-experiments/demo/hudi/hudi_trade_info_derived_cow:()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "var result = (incrementalDF.write.format(\"hudi\")\n",
    "      .options(getQuickstartWriteConfigs)\n",
    "      .option(TABLE_TYPE_OPT_KEY, dsWriteOptionType)\n",
    "      .option(TABLE_NAME, targetTableName)\n",
    "      .option(RECORDKEY_FIELD_OPT_KEY, hudiTableRecordKey)\n",
    "      .option(PARTITIONPATH_FIELD_OPT_KEY,hudiHiveTablePartitionKey)\n",
    "      .option(PRECOMBINE_FIELD_OPT_KEY, hudiTablePrecombineKey)\n",
    "      .option(KEYGENERATOR_CLASS_OPT_KEY, classOf[ComplexKeyGenerator].getName)     \n",
    "      .option(HIVE_STYLE_PARTITIONING_OPT_KEY, \"true\")\n",
    "      .option(HIVE_SYNC_ENABLED_OPT_KEY, \"true\")\n",
    "      .option(HIVE_TABLE_OPT_KEY, targetTableName)\n",
    "      .option(HIVE_PARTITION_FIELDS_OPT_KEY, hudiHiveTablePartitionKey)\n",
    "      .option(HIVE_PARTITION_EXTRACTOR_CLASS_OPT_KEY, classOf[MultiPartKeysValueExtractor].getName)\n",
    "      .option(HIVE_DATABASE_OPT_KEY, hudiDatabaseName)\n",
    "      .option(\"hoodie.metadata.enable\", \"true\")\n",
    "      .option(\"hoodie.index.type\",\"GLOBAL_BLOOM\")\n",
    "      .mode(\"append\")\n",
    "      .save(targetHudiTablePath));\n",
    "\n",
    "println(\"Saved data \"+targetHudiTablePath+\":\"+result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ceba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
