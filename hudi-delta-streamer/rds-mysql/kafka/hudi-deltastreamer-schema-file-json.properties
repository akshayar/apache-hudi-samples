# Key fields, for kafka example
hoodie.datasource.write.recordkey.field=tradeId
hoodie.datasource.write.partitionpath.field=symbol
hoodie.datasource.write.hive_style_partitioning=true
hoodie.datasource.write.keygenerator.class=org.apache.hudi.keygen.ComplexKeyGenerator
hoodie.datasource.hive_sync.table=${HUDI_TABLE_NAME}
hoodie.datasource.hive_sync.database=demohudi
hoodie.datasource.hive_sync.partition_fields=symbol
hoodie.datasource.hive_sync.use_jdbc=false
hoodie.datasource.hive_sync.mode=hms
hoodie.metadata.enable=false
hoodie.index.type=GLOBAL_BLOOM
hoodie.datasource.hive_sync.partition_extractor_class=org.apache.hudi.hive.MultiPartKeysValueExtractor
#hoodie.datasource.hive_sync.partition_extractor_class=org.apache.hudi.hive.NonPartitionedExtractor
# Kafka Source
hoodie.deltastreamer.source.kafka.topic=${KAFKA_TOPIC}
#Kafka props
bootstrap.servers=${KAFKA_BOOTSTRAP}
auto.offset.reset=earliest
# schema provider configs
hoodie.deltastreamer.filebased.schemaprovider.source.schema.file=s3://${S3_BUCKET_FOR_JAR}/hudideltastreamer/TradeData.avsc
hoodie.deltastreamer.schemaprovider.source.schema.file=s3://${S3_BUCKET_FOR_JAR}/hudideltastreamer/TradeData.avsc
